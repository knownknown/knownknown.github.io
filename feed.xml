<?xml version="1.0" encoding="utf-8" ?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>   
    <title>near-perfect clarity</title>
    <atom:link href="http://knownknown.github.io/feed.xml" rel="self" type="application/rss+xml"></atom:link>
    <link>http://knownknown.github.io</link>
    <description>there will be near-perfect clarity</description>
    <pubDate>Thu, 17 Sep 2015 20:00:00 -0400</pubDate>
    <generator>The mighty Wintersmith</generator>
    <language>en</language>
    <item>
      <title>How meaningful are early primary polls?</title>
      <link>http://knownknown.github.io/articles/05_primaries/</link>
      <pubDate>Thu, 17 Sep 2015 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/05_primaries/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Early primary polls have been getting a lot of attention as the GOP race enters the debate stage. Or, more precisely, they’ve been getting attention as the GOP embarks on it’s decennial ritual where a member of the Bush clan is forced to run for president while being harassed by a self-funded billionaire who has “MAKE ‘EM THINK YOU’RE CRAZY!” right in the center of his vision board (no, not &lt;a href=&quot;https://en.wikipedia.org/wiki/Ross_Perot&quot;&gt;that one&lt;/a&gt;, or &lt;a href=&quot;https://en.wikipedia.org/wiki/Steve_Forbes&quot;&gt;that one&lt;/a&gt;). This year, the network hosting the opening debates even went so far as to use early polling to determine what kind of airtime and stage formation a candidate would receive. But the value of such polls remains in contention, with political scientists furrowing their brows and demanding that we &lt;a href=&quot;http://www.bloombergview.com/articles/2014-12-16/poll-surges-for-2016-candidates-dont-mean-much&quot;&gt;ignore early polls entirely&lt;/a&gt;, while political journalists &lt;a href=&quot;http://www.washingtonpost.com/blogs/monkey-cage/wp/2015/07/27/early-polls-dont-mean-much-its-still-possible-to-report-on-them/&quot;&gt;complain&lt;/a&gt; that the geeks are ruining all the fun and compare poll skepticism to a sports fan only wanting to watch the last 2 minutes of a sporting event. I’ll pause here to note that the sports analogy pretty much misses the point: if only the last two minutes of a sporting event were predictive of outcome, then it would indeed be bad journalism to write long think-pieces about how the team leading the second quarter (or period or whatever) is slated for a historic victory that will reshape sports forever. One can still write about the strategies the two teams are using; the performance of certain key players relative to previous games; the refereeing; or even the fan response; but if the current score has no relationship to the final score, then no amount of enthusiastic analysis is going to make it useful. So the question is, how meaningful are early polls?&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the geeks have data on their side. At least one &lt;a href=&quot;http://themonkeycage.org/2011/05/do-early-polls-predict-anything/&quot;&gt;study&lt;/a&gt; has demonstrated that general election polls &amp;gt;1 year away are complete un-predictive of eventual outcome. A similar &lt;a href=&quot;http://fivethirtyeight.com/features/theres-no-perfect-way-to-sort-the-candidates-for-a-primary-debate/&quot;&gt;analysis&lt;/a&gt; of February-July primary polling shows this to be the case in party nominations as well. However, while looking at the variance in outcome that can be explained by early polling is statistically sound, it can yield an overly pessimistic result by giving equal weight to minor candidates. Does it really matter that the polls got Huckabee and Santorum wrong if they still got Romney right? What we care about is the winner, so the most basic metric is how often the front-runner in early polls predicts the eventual winner. I don’t believe this has been looked at in detail, and I’ve quantified it here using historical polling data for 21 primaries.&lt;/p&gt;
&lt;h3 id=&quot;early-polls-in-the-legacy-primary-era-not-great&quot;&gt;Early polls in the legacy primary era - not great&lt;/h3&gt;
&lt;figure class=&quot;right&quot;&gt;
&lt;img src=&quot;1952_stevenson_pin.jpg&quot; alt=&quot;image&quot; width=200px style=&quot;margin:5px&quot; /&gt;
&lt;figcaption&gt;&lt;em&gt;Stevenson ‘52 campaign pin: gets right to the point&lt;/em&gt;&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Since we’re looking at primaries, it’s important to consider the major shift in primary structure that happened in the 1970’s. The two parties moved from a selection contest lead by party bosses to a large number of binding state-based votes. The states in turn tried to maximize their influence by organizing into regional blocks or vying for earlier elections. To give you an idea of how different the world was, the eventual winner of the 1952 primary didn’t even run until the convention! Illinois Governor Adlai Stevenson II was encouraged by many party leaders (including President Truman) to run in the primary but repeatedly declined. At the convention, which was held in his state, his welcome address was so well-received that the party bosses were able to convince him to enter his name into the selection process. Though initially scoring well below the front-runner Estes Kefauver (who had &amp;gt;40% in the popular polls at the time), Stevenson went on to win the nomination after two run-off votes. Stevenson essentially received the presidential nomination with zero public campaigning. In the modern era, this would be like Barack Obama getting the 2004 nomination because he gave a pretty good speech to lead off the convention (but I guess that Obama fellow did alright anyway).&lt;/p&gt;
&lt;p&gt;Below are the results from races in the pre-1980’s era. The top five performers (which always included the front-runners and the winners) are shown from each race, with the eventual winner plotted in black. The figures are ordered chronologically, and each one starts 30 months prior to the party convention, where the nominee is selected, and move towards the convention as you go from left to right. Individual poll results are shown as points and also locally smoothed into trendlines. Finally, the overall trend is shown in the bottom-right and also broken down by party (Red Republicans and Blue Democrats).&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;legacy_polls.svg&quot; alt=&quot;image&quot; width=900px /&gt;
&lt;figcaption&gt;&lt;em&gt;Primary polling trends from the pre-1980 era&lt;/em&gt;: Polls become more predictive than initial standings at -20 months (R) and -10 months (D).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Overall, the polls show a steady increase in predictability starting at about -15 months and hitting 80% (my completely arbitrary threshold for “good”) at -5 months. Notably for Democrats, out of four races only John F. Kennedy was both initial front-runner and winner. Aside from Eisenhower and Kennedy, the races were surprisingly contentious, with the winners closely trailed by their competition throughout the race.&lt;/p&gt;
&lt;h3 id=&quot;early-polls-in-the-modern-primary-era-also-not-great&quot;&gt;Early polls in the modern primary era - also not great&lt;/h3&gt;
&lt;p&gt;With the the modern primary era shifting power away from the party bosses and to the states, we might expect the races to get more “democratic” and polling (which has also improved in rigor over time) to become more predictive. Below are the results from races in the post-1980’s era.&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;modern_polls.svg&quot; alt=&quot;image&quot; width=900px /&gt;
&lt;figcaption&gt;&lt;em&gt;Primary polling trends from the post-1980 era&lt;/em&gt;: Polls become more predictive at -5 months (R) and -10 months (D).&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Let’s focus on the general trends by party. Even though Democrats ushered in the state-oriented primary, the trend for them actually changed very little. Democratic voters tend to pick the wrong guy more often than not until about -10 months, at which point the polling quickly moves to the eventual winner. For Republicans the modern trend is a bit more interesting. First, the initial front-runner became much more favored to win the nomination, from 50% of the time in the legacy era to 80% of the time now. Even in the one election where the front-runner was not the winner (2008, with McCain lagging but eventually overtaking Giuliani) the two started out in a statistical tie. Second, the Republican polls actually appear to get &lt;em&gt;worse&lt;/em&gt; than initial polls in the -20 to -5 months period, primarily driven by the false waves of 2008/2012. The monthly polling interval actually understates this dip for the &lt;a href=&quot;http://elections.huffingtonpost.com/pollster/2012-national-gop-primary&quot;&gt;2012 primary&lt;/a&gt;, where almost every candidate was temporarily front-runner. If these last two races are the start of a pattern, we should be especially skeptical of polls in this time-frame, particularly when they differ greatly from the initial front-runner.&lt;/p&gt;
&lt;h3 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h3&gt;
&lt;p&gt;The results from the modern era seem to contradict themselves. On the one hand, early polling is quite predictive of eventual outcome, at least for Republicans. On the other hand, the predictiveness stagnates for months and even gets less predictive for a time until ~5 months prior to the convention. Both of these statements are true and thus allow for the philosophical gap between political scientists and journalists to persist.&lt;/p&gt;
&lt;p&gt;Returning like a dog to it’s vomit to the sports metaphor, imagine that professional basketball games now have a half-time dunk contest between the players. This shoot-out is weakly predictive of what will happen in the second half - for example, players that tripped and fell during their dunk were likely to do poorly later in the game - but it’s much less predictive than the actual score from the first half. And now imagine that sports journalists spent an inordinate amount of time discussing the dunk contest and what it meant for the second half; reviewed dunks in slow-motion; comparing dunk performance to historic trends; etc. All at the cost of actually interviewing coaches about their strategies or consulting with experts about that first-half fundamentals were important. The side-show has become the main event.&lt;/p&gt;
&lt;p&gt;In general, I think it’s hard to appreciate the fact that that how the public feels now is actually &lt;em&gt;less&lt;/em&gt; representative of the future than how they felt yesterday. We tend to think of voters as a machine that slowly becomes more informed as it converges on the preferred candidate. And that “meaningless” -20 to -5 month period contains a ton of data - rallies, multiple debates, press-conferences. But in recent history Republican voters actually make up their mind early on, then grope in the dark for other plausible candidates, and finally accept the one they chose from the beginning. While Democrats grope around the whole way through. For a journalist to accept the futility of daily poll fluctuations during this period would also mean accepting, at least in part, the pointlessness of their own their reporting in guiding the public to their eventual decision.&lt;/p&gt;
&lt;p&gt;So what does this mean for the 2016 primary? For Democrats, it means that Hillary Clinton’s lead is not assured, and  that a repeat of 2008 is still entirely possible. For Republicans, it means Mike Huckabee - who lead in Jan 2014 - is certainly going to be the next nominee. No but seriously, it means that the groping in the dark period now extends even further back than before, and Jeb Bush - the only candidate that has held a consistent baseline of support - is likely to be the eventual winner. For us, it means to ignore those polls until the start of 2016. With more polling data, it would be interesting to breakdown the electorate into key demographics and see if any are particularly good at picking the eventual winner.&lt;/p&gt;
&lt;h3 id=&quot;appendix-data-details&quot;&gt;Appendix: Data details&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Some amount of data massaging was required to get everything working without having to read through thousands of individual poll questions. I downloaded all polls from Gallup that contained the text “Republican candidate for president” or “Republican nomination for president” (likewise for Democrats) and tried to exclude as many “second choice” or leaner answers as I could find. Races that did not have at least 12 polls were excluded. For each race, candidates that were not queried in &amp;gt;50% of the polls were excluded. Of the remaining candidates, the top five by average poll % were plotted, with the eventual winner always shown in black. Though the Gallup archive primarily had monthly polling, polls that were taken in in the same month were plotted separately (and therefore averaged in the fit curve). For the average across all races, the first and last poll results were extended backward/forward to 30 months, and races that did not have a poll in a given month were interpolated from the previous month. In all plots smoothing was done by simple LOESS curve fitting.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WL4 - Classified status</title>
      <link>http://knownknown.github.io/articles/04_classified/</link>
      <pubDate>Wed, 30 Apr 2014 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/04_classified/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;em&gt;Meta information on the diplomat classifying each cable reveals many significant dipomat-to-entity associations. Analyzed as a graph, these associations provide a comprehensive view of major agency priorities and their overlap.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is part #4 in an ongoing series describing data analyses of the Wikileaks cables.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One of the conveniences of this data is that it follows a structured form with several important pieces of meta-information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Send date (which we’ve looked at previously)&lt;/li&gt;
&lt;li&gt;Subject.&lt;/li&gt;
&lt;li&gt;Origin and destination (surprisingly unimportant, with cables typically originating from a US Mission in the host country and destined for general federal departments)&lt;/li&gt;
&lt;li&gt;TAGS (very generally describing the cable contents, e.g. “External Political Relations”, “Military and Defense Arrangements”, etc.)&lt;/li&gt;
&lt;li&gt;Classification status.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;An ignored data point (as far as I am aware) has been the classification status, which includes a sentence stating the person who classified it and the formal reasons. The &lt;a href=&quot;http://en.wikipedia.org/wiki/Classified_information_in_the_United_States#Classification_categories&quot;&gt;reasons themselves&lt;/a&gt; are  general, but the diplomat setting the classification essentially takes ownership of the cable. They may not be the original author (as cables are often drafted by lower-level diplomats) but they are the last person in charge once the cable leaves it’s origin. Looking for patterns across these individuals can provide insights into the structure of embassy work and the distribution of labour. And unlike assumption-free analysis of the text, these patterns represent priorities set by the department &lt;em&gt;itself&lt;/em&gt;. Instead of guessing what content was deemed important, we can learn these priorities directly. Which entities are most discussed by individuals within the department? Do they tend to work together or focus on topics individually? Which topics had focus and when? With the classification data, these questions can now be tested directly.&lt;/p&gt;
&lt;h3 id=&quot;individual-associations&quot;&gt;Individual associations&lt;/h3&gt;
&lt;p&gt;Perhaps one of the oldest statistical &lt;a href=&quot;http://en.wikipedia.org/wiki/Student%27s_t-test&quot;&gt;tests&lt;/a&gt; evaluates differences between two sets of data, or an &lt;em&gt;association&lt;/em&gt; between an indicator and an outcome. We can apply such techniques to this data in looking for an association between classifiers and specific topics. As with any fundamental question, there are dozens of ways to answer it, but to start I simply counted the fraction of times an entity (say “Bosnia”) is mentioned by a specific classifier and compared it to the fraction in the rest of the classified data. If the classifier mentioned Bosnia much more or less than everyone else, we can assess the significance of this deviation. Since we’re working with small count data, the Fisher’s Exact Test is appropriate in evaluating significance. This way, every classifier was tested against every entity they classified, and the final outcome was &lt;a href=&quot;http://en.wikipedia.org/wiki/Bonferroni_correction&quot;&gt;corrected&lt;/a&gt; for all the tests performed to make sure we weren’t just pulling out random patterns because we rolled the dice so many times.&lt;/p&gt;
&lt;p&gt;Turns out the data is highly structured, and the top ten classifiers (which had &amp;gt;100 cables each) all strongly associated with many terms. Below is the set of significant associations for the LOCATION category:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.5.png&quot; alt=&quot;LOCATION&quot;&gt; &lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.6.png&quot; alt=&quot;LOCATION&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.10.png&quot; alt=&quot;LOCATION&quot;&gt; &lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.8.png&quot; alt=&quot;LOCATION&quot;&gt;   &lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.3.png&quot; alt=&quot;LOCATION&quot;&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.2.png&quot; alt=&quot;LOCATION&quot;&gt; &lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.1.png&quot; alt=&quot;LOCATION&quot;&gt; &lt;img src=&quot;http://knownknown.github.io/articles/04_classified/assoc.LOCATION.4.png&quot; alt=&quot;LOCATION&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The red bar corresponds to the fraction of mentions received by that entity, and the black bar is the fraction in the rest of the data. These associations are not just significant, but are also very strong in absolute terms; almost every diplomat has a topic that they discuss &lt;em&gt;much&lt;/em&gt; more than the rest. Looking for relationships between the entities, we can guess at some broad topics: Charles English &amp;amp; Judith Cefkin focus on Bosnia, Serbia, and Yugoslavia; Jerry Taylor on Ukraine and Belarus; Eric Schultz on the south-stream pipeline route spearheaded by Gazprom, with construction starting in Krasnoyarsk; etc.&lt;/p&gt;
&lt;p&gt;The overall departmental structure appears to be fairly divided, with one or two individuals focusing on each of these topics. Looking at all the topics together also fleshes out the general shape of the Russian conversation. Topics that we had previously guessed as important - Georgia, Bosnia - are now confirmed as important for specific high-level individuals, and others - such as Russian oil resources - are now on the radar.&lt;/p&gt;
&lt;h3 id=&quot;from-associations-to-relationships&quot;&gt;From associations to relationships&lt;/h3&gt;
&lt;p&gt;Going beyond the individual diplomat-entity associations, we can try to visualize all of these relationships together by placing them in a graph (you knew this was coming, right? At least it’s not one of those animated, spring-loaded nightmares. But be sure to zoom in for detail):&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;graph.svg&quot; alt=&quot;image&quot; width=900px /&gt;
&lt;/figure&gt;

&lt;p&gt;So what’s going on here? Each node represents an entity (PERSON, LOCATION, or ORGANIZATION), and every pair of nodes has an edge weight corresponding to the number of cables they both appear in. Nodes that never appear together have a weight of zero, and so on. To preserve our sanity, only those nodes that were significantly positively associated with at least one diplomat have been plotted here, and their colours correspond to the most associated diplomat. This is expected to create a distortion in the graph, since we’re selecting precisely those entities that are polarizing, but that’s actually &lt;em&gt;desireable&lt;/em&gt;. We’re specifically interested in identifying strata which correlate with individual diplomats, and so letting the associated nodes drive the graph structure encourages this. Nodes are also scaled according to their PageRank, which basically measures how many other large nodes each node is connected to. Finally, after everything is laid out the edges are hidden for clarity (as is often the case, they’re &lt;a href=&quot;http://knownknown.github.io/articles/04_classified/graph.edges.png&quot;&gt;pretty&lt;/a&gt; but mostly meaningless; the one useful observation is that the neighbouring Gottemoeller and English nodes are mostly independent). I’ll add a caveat that many of the attractive qualities (the spherical shape, the spacing between nodes) are an artefact of the layout algorithm, so one should be careful not to draw conclusions like “&lt;em&gt;diplomatic communications are naturally geometrically circular&lt;/em&gt;“ or some-such.&lt;/p&gt;
&lt;p&gt;That said, the final network is highly informative and crystallizes our previous term-based guesses. A small number of primary groups are clearly visible:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rose Gottemoeller: New START; Geneva (the site of the negotiations); SLBMS (ballistic missiles); NPT (non-proliferation treaty); and various Russian and US negotiators.&lt;/li&gt;
&lt;li&gt;Charles English: Serb/Bosnian relations; Miloard Dodik, the president of Republika Srpska; SDA (The Bosnian Party of Democratic Action); and Srebrenica. There is also strong overlap with diplomat Judith Cefkin.&lt;/li&gt;
&lt;li&gt;Jerry Taylor: Ukraine, Kazakhstan, and Belarus; apparently strong overlap with the Gottemoeller/New START work (through the JCIC - Joint Compliance and Inspection Commission).&lt;/li&gt;
&lt;li&gt;Eric Schultz: finance and natural resources, focusing on Gazprom and Lukoil.&lt;/li&gt;
&lt;li&gt;John Beyrle &amp;amp; Alice Wells: the Georgian war. With Wells focusing on Russian media (the newspapers Kommersant, Novaya Gazeta, Nezavisimaya Gazeta); reform movements (Kasparov, Nemtsov, the progressive Yabloko and Union of Right Forces parties) and hard-liners (far-right LDPR, communist KPRF parties).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As we suspected most, cables focus on topics related to New START negotiations, the Orange Revolution in Ukraine, Bosnian statehood, and the Georgian war; and each topic is helmed by one or two diplomats. Now that the overall layout is understandable to us, we can add in the time dimension and see how nodes have changed through the 2006-2010 period. The &lt;a href=&quot;http://knownknown.github.io/articles/04_classified/time_graph.gif&quot;&gt;animated graph&lt;/a&gt; (warning, large-ish file) reveals additional trends: a persistent focus on the Bosnian issue; the late-2009/early-2010 focus on New START and missile defense; near-total focus on the Georgian war in 08/2008, with little fore-warning; an initial focus on natural resources and Moscow politics that nearly disappears by 2010.&lt;/p&gt;
&lt;h3 id=&quot;graph-or-trap-&quot;&gt;Graph or trap?&lt;/h3&gt;
&lt;p&gt;I’ll admit that I’ve dreaded looking at the data in this massive graph form. Such visualizations tend to be extremely attractive and carry the &lt;em&gt;appearence&lt;/em&gt; of information, but often confuse more than they inform. Usually, the viewer is awed by the complexity of the data and then moves on with their day. Perhaps they see a few clusters or over-represented colours and think “&lt;em&gt;This data sure is complex. But it’s also structured.&lt;/em&gt;“, having learned no more than what could be presented by a handful of statistics. That may be even worse.&lt;/p&gt;
&lt;p&gt;To make sure we’re not just being seduced by &lt;a href=&quot;http://eagereyes.org/techniques/graphs-hairball&quot;&gt;hairballs&lt;/a&gt; it’s useful to think about how much more information we’ve &lt;em&gt;really&lt;/em&gt; gained over looking at the data in sorted tables. The main contribution of the graph is in summarizing the proximity of terms. For example, many seemingly general terms  - elliott, smith, gross, dean - now come out as corresponding to the New START negotiations. Distance is also revealed: we see that Diplomat Wells focuses both on topics relating to the Georgia war (sakkashvili, tskhinvali) as well as unrelated issues such as Russian newspapers. Lastly, we can get a sense of the complexity of each topic: the Georgian issue is driven by a handful of major entities; while New START includes many equally represented individuals and concepts; and Bosnian statehood is somewhere in between.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WL3 - Time Series</title>
      <link>http://knownknown.github.io/articles/03_time_series/</link>
      <pubDate>Mon, 28 Apr 2014 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/03_time_series/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;em&gt;Examining the distribution of cables and entities over time provides important context and identifies a small number of well-documented entities that are likely to be important. However, we’re still not capturing the direct relationships between these entities.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is part #3 in an ongoing series describing data analyses of the Wikileaks cables.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In the previous post, a naive list of highly occurring entities provided some sense of the diversity of this data as well as a condensed “Top 10” of the people, locations, and organizations discussed in the cables. One dimension that’s entirely missing from that approach is that of time. Each cable has been coded with a time-stamp for when it was sent, allowing us to look at the frequency of communication across the available time-frame. To get a birds eye view of all cables, I’ve plotted their number over consecutive 10-day periods, with the year breaks indicated:&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;http://knownknown.github.io/articles/03_time_series/time_ser.total.png&quot; alt=&quot;time-series total&quot;&gt;
&lt;/figure&gt;

&lt;p&gt;It’s immediately obvious that the bulk of the cables were gathered from 2006-2010. We can similarly zoom in on cables mentioning specific entities and examine their time series. As an example, let’s take a look at occurrences over time for two of the previously identified common words “Saakashvili” (the president of Georgia) and “South Ossetia” (the disputed, formerly Georgian, territory). The representation is the same as before, but I’ve also highlighted the explicit start of the Russo-Georgian War in August, 2008:&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;http://knownknown.github.io/articles/03_time_series/time_ser.example.png&quot; alt=&quot;time-series South Ossetia example&quot;&gt;
&lt;/figure&gt;

&lt;p&gt;Lo and behold, we see a substantial up-tick in mentions of both entities at the start of the war. This visualization makes it clear that the great number of Saakashvili mentions is almost entirely explained by events of late 2008. We can also see that both entities were mentioned regularly but infrequently in the preceding years, and that the increase in mentions subsided almost entirely by the start of 2009, particularly for Saakashvili. That the spike in mentions happened in the same week as the deceleration of war (even though tensions between Georgia and Russia had been high since at least April) suggests that US diplomats were not unusually focused on the issue prior to military escalation. Just looking at these occurrences over time has provided a great deal of context.&lt;/p&gt;
&lt;p&gt;Similarly, we can look at common entity occurrence surrounding the March, 2008 election of pint-sized president Dimitri Medvedev:&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;http://knownknown.github.io/articles/03_time_series/time_ser.example2.png&quot; alt=&quot;time-series Medvedev example&quot;&gt;
&lt;/figure&gt;

&lt;p&gt;In this instance, the increase in mentions of Medvedev preceded his election by months (starting around the time of his nomination in January, 2008), indicative of some advanced knowledge. On the other hand, the nearly complete lack of mentions prior to 2008 suggests that he had not recently been a key diplomatic figure. In comparison, Putin is discussed consistently throughout the entire analysed period and his stature is largely unaffected after being replaced by Medvedev.&lt;/p&gt;
&lt;h3 id=&quot;broader-trends&quot;&gt;Broader trends&lt;/h3&gt;
&lt;p&gt;Looking at a small number of entities is clearly informative, but somewhat unrealistic; in the above examples we started with a known event and looked at it in relation to certain known entities. What we actually want is the complete opposite: start with a pile of unknown data and have the analyses reveal both the important entities &lt;em&gt;and&lt;/em&gt; the events they are linked with. This turns out to be more difficult that it first seemed. If we simply look at the most mentioned entities in each month, we tend to see individuals that appear consistently throughout the time-line or their administration. As in the Putin example above, discussion of these individuals (Medvedev, Lavrov, Obama, etc.) doesn’t vary much over time, and so the time-dimension becomes uninformative. At best, we’ll know when someone big has come into office; at worst, we’ll just have a messier version of the “Top 10” list. We can deal with this by normalizing each entity by their total number of occurrences and then look for monthly peaks, but that shifts the data too much in the direction of minorities. After normalization, someone who gets 1,000 mentions in Jan. and Feb. ranks below someone who gets 2 mentions in Jan. only, so individual blips get hugely inflated.&lt;/p&gt;
&lt;p&gt;The working solution is to use a hybrid of the two strategies: first the blips are weeded out, then the remaining important entities are normalized and compared. For every month, we identify all entities that are the most mentioned - these are important enough to show up frequently &lt;em&gt;at some point in time&lt;/em&gt;.  We can then tune the monthly inclusion threshold to select the desired number of entities in total. After selecting this set of core individuals we normalize them and examine their occurrences over time. The approach is &lt;em&gt;ad hoc&lt;/em&gt; in the inclusion, but that will primarily effect the overall number of samples viewed.&lt;/p&gt;
&lt;p&gt;Below is the horizon plot for LOCATION entities:&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;http://knownknown.github.io/articles/03_time_series/time_ser.LOCATION.png&quot; alt=&quot;LOCATION distribution&quot;&gt;
&lt;/figure&gt;

&lt;p&gt;Fundamentally, this is not much different from a heat-map or “small-multiples” chart, but it provides more granularity than the former while still being very efficient. One concern is that the &lt;em&gt;ordering&lt;/em&gt; of individual rows can affect the interpretation, and here they have been grouped using simple hierarchical clustering. This tends to place similar trend-lines together so that correlations are easier to pick out by eye (though it is far from perfect). Continuing from the previous example, we see that “South Ossetia”, “Abkhazia”, and “Georgia” all cluster together and are driven by a peak around the August ‘08 War.&lt;/p&gt;
&lt;p&gt;We can similarly examine the time series of top PERSON entities:&lt;/p&gt;
&lt;figure class=&quot;full&quot;&gt;
&lt;img src=&quot;http://knownknown.github.io/articles/03_time_series/time_ser.PERSON.png&quot; alt=&quot;PERSON distribution&quot;&gt;
&lt;/figure&gt;

&lt;p&gt;Several general time-related topics are starting to emerge. We can clearly see the changing administrations in 2009 as the mentions of Secretary Rice are replaced by Barack Obama, Hilary Clinton, and Rose Gottemoeller (Assistant Secretary of State for the Bureau of Arms Control, Verification and Compliance). We also see a 2007 cluster of Bosnian politicians (Ivanic, Tihic, Silajdzic) likely related with Ahtisaari, the UN envoy for the Kosovo status process. Also interesting is the consistent presence of Milorad Dodik. Dodik was one of the surprising entities at the top of all cables, and it’s clear now that this was not a fluke or due to a single key date.&lt;/p&gt;
&lt;h3 id=&quot;discussion&quot;&gt;Discussion&lt;/h3&gt;
&lt;p&gt;Looking at the data across time also makes clear it that we’re still missing &lt;em&gt;a coherent, time-coded context for each of the well-represented entities&lt;/em&gt;. Many context-specific questions remain unanswered: What is being discussed in the flurry of cables on Milorad Dodik at the end of 2008? Are the punctuated entities (e.g. Elisabeth Millard and Stephen D Krasner) co-occurring by chance or do they have a relationship? In short, does each of these rows represent an individual event or just one strand from a complex, correlated community? We’ve gained some intuition by looking at occurrences over time, but these questions can only be answered by broadening our analysis to &lt;em&gt;co-occurrences&lt;/em&gt; of entities within cables and across time.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WL2 - A Brief Note on Sentiment</title>
      <link>http://knownknown.github.io/articles/02_sentiment/</link>
      <pubDate>Tue, 22 Apr 2014 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/02_sentiment/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;em&gt;Inferring the emotional content of text opens up very cool possibilities, but it’s just not appropriate for data with this level of nuance and complexity.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is part #2 in an ongoing series describing data analyses of the Wikileaks cables.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One of the more exciting NLP applications to this data is “sentiment” analysis, which aims to automatically classify sentences and entities with the writer’s contextual emotions. Naively, one could this by simply taking a set of words with known sentiment scores (“happy”=positive, “awful”=negative, etc.) and counting up their occurrences to get an overall sentence or document score (the so-called &lt;em&gt;bag of words&lt;/em&gt; model which ignores word order and grammar). This has some obvious draw-backs (“he was happy to spit in our face”, “we had an awfully good time”) and has been heavily extended to take into account local and even multi-sentence context. The Stanford &lt;a href=&quot;http://nlp.stanford.edu/sentiment/&quot;&gt;Recursive Model&lt;/a&gt;, for example, turns the sentence into a tree using parts-of-speech, then builds a combined score from the leaves up. Perhaps “awfully good” could be correctly understood as single positive phrase instead of one positive word and one negative word. If the algorithm works, the implications can be tantalizing; see, for example, the IKANOW &lt;a href=&quot;http://www.ikanow.com/making-the-most-of-sentiment-scores-with-ikanow-and-r/&quot;&gt;analysis&lt;/a&gt; of Enron e-mails; and Saif Mohammad’s time-series &lt;a href=&quot;http://www.saifmohammad.com/WebDocs/NRC-TechReport-emotions-in-books-and-mail.pdf&quot;&gt;analysis&lt;/a&gt; of sentiment in books. In the context of diplomatic data, quantifying sentiment would express in numbers the cloud of emotions surrounding those actors and organizations we’re studying:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What individuals are the most/least liked?&lt;/li&gt;
&lt;li&gt;How has that changed over time?&lt;/li&gt;
&lt;li&gt;Which are the most controversial, liked and hated in equal measure?&lt;/li&gt;
&lt;li&gt;Which diplomats are unusually friendly to some individuals but not others? This last one is especially important as it provides insight into the potential biases of our narrators.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This emotional content may be even more informative than the factual, especially when the data has been heavily ascertained from one point-of-view. As it happens, bag-of-words sentiment analysis has been applied to such data to quantify U.S. relationships with foreign nations (&lt;a href=&quot;http://www.technologyreview.com/view/423601/automated-processing-of-wikileaks-cables-reveals-us-friends-foes/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://vikparuchuri.com/blog/tracking-us-sentiments-over-time-in/&quot;&gt;here&lt;/a&gt;). Those projects are novel and the application clever, but the results are clearly noisy and not particularly informative without many assumptions. Perhaps we could do better by using a more advanced sentiment parser; analysing a single region where word-choice is more likely to be controlled; linking the sentiment to known political actors, and looking at a generally richer dataset.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s start with the good news. Here are some example sentences that had the highest sentiment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Analysts predict several decades of sustained robust economic growth, thanks in part to India’s youthful population and its technical and scientific prowess.&lt;/li&gt;
&lt;li&gt;USAID post-tsunami reconstruction projects are moving ahead smartly.&lt;/li&gt;
&lt;li&gt;He has good Kremlin access and a well-developed sense of what is realistic in light of Kremlin policies.&lt;/li&gt;
&lt;li&gt;He and President Putin are very popular and receive credit for Belgorod’s strong economy, active civil society, and vibrant academia.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the second instance we almost certainly got lucky that some other British-ism hadn’t been used instead of “smartly” (say, “briskly”). And the last two examples are nuanced in the real subject of their approval. But let’s not quibble, these are really quite positive!&lt;/p&gt;
&lt;p&gt;The bad news, though, is that these examples are pretty much the only true positives (in every sense of the word) over the tens of thousands of sentences that received sentiment scores before my computer said “enough”. Nearly every sentence was given a negative score, and examining individual cables that had extreme sentiment averages showed no indication of accuracy. If anything, the average sentiment was mostly representative of cable size and complexity (which makes sense, as the sentiment parser appears to down-weight complex sentences with positive words). None of the most negatively ranked cables I looked at could reasonably be interpreted as accurately classified. This, coupled with the fact that sentiment analysis is easily the most computationally intensive part of the language analysis, lead me to reluctantly abandon the strategy.&lt;/p&gt;
&lt;p&gt;Sentiment analysis clearly has value, and sentiment-based predictors of everything from &lt;a href=&quot;http://www.lct-master.org/files/MullenSentimentCourseSlides.pdf&quot;&gt;music reviews to twitter messages&lt;/a&gt; already do very well. But pulling out emotional terms from 140 characters appears to be a much easier problem that annotating large, nuanced political documents.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WL1 - Named Entities</title>
      <link>http://knownknown.github.io/articles/01_named_entities/</link>
      <pubDate>Mon, 21 Apr 2014 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/01_named_entities/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;em&gt;Extracting important entities from the text is a useful first step and provides a birds-eye view of all the content. But what we’re interested in is most likely at the margins.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is part #1 in an ongoing series describing data analyses of the Wikileaks cables.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The entire Cablegate release consists of over 250,000 cables from a 20 year period, over a gigabyte of full-text storage. To get a sense of the data, these initial analyses will focus on the 8,000 cables tagged “RS”, corresponding to communication about Russia and neighbouring countries. Russia was chosen for several reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It’s one of the single most-mentioned countries outside of the Middle East. At the same time, it appears to be strongly under-reported, as news agencies focused on cables relating to Iraq and Afghanistan or colourful personalities.&lt;/li&gt;
&lt;li&gt;It’s an extremely important American adversary, with several major geo-political events (such as the Georgian War) occurring during the leaked time-frame. As a consequence, it features key players and organizations that are mostly well-known in the West.&lt;/li&gt;
&lt;li&gt;It’s continued to engage in military activity that strongly mirrors the events of the Georgian War, and so there is hope that diplomatic communications from that time will inform our understanding of current events.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first step in analysing so much text is breaking it down into major concepts and establishing their relationships. Concepts can be difficult to pin down, but the automated extraction of specific objects has been well-developed in the field of Natural Language Processing (NLP). Termed Named Entity Recognition (NER), such methods use sentence context and parts-of-speech to identify specific categories of words (typically nouns) based on a training set. For this data, I applied the &lt;a href=&quot;http://nlp.stanford.edu/software/CRF-NER.shtml&quot;&gt;Stanford NER&lt;/a&gt; to extract PERSON, LOCATION, and ORGANIZATION entities based on a training set of newspaper text. We’re lucky that most of the cables are written in newspaper style, so the training set is a good match. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Top entities&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Russia/RS cables tagged consist of 7,803 locations; 19,105 organizations; and 20,680 persons. Roughly a quarter of the entities appear in at least two cables, and I’ll focus on these for now as they are less likely to be false identifications. A total of 280 (2%) unique entities account for 50% of the entity-to-cable relationships. The most over-represented entities are:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;LOCATION&lt;/th&gt;
&lt;th&gt;ORGANIZATION&lt;/th&gt;
&lt;th&gt;PERSON&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;6.7% russia&lt;/td&gt;
&lt;td&gt;2.6% mfa&lt;/td&gt;
&lt;td&gt;2.9% putin&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5.5% us&lt;/td&gt;
&lt;td&gt;2.1% eu&lt;/td&gt;
&lt;td&gt;1.9% medvedev&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4.5% moscow&lt;/td&gt;
&lt;td&gt;2.0% nato&lt;/td&gt;
&lt;td&gt;1.1% lavrov&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.0% united states&lt;/td&gt;
&lt;td&gt;1.4% un&lt;/td&gt;
&lt;td&gt;0.7% obama&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.9% georgia&lt;/td&gt;
&lt;td&gt;1.1% osce&lt;/td&gt;
&lt;td&gt;0.7% gottemoeller&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.5% washington&lt;/td&gt;
&lt;td&gt;0.8% gazprom&lt;/td&gt;
&lt;td&gt;0.6% saakashvili&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.5% eu&lt;/td&gt;
&lt;td&gt;0.6% ngo&lt;/td&gt;
&lt;td&gt;0.5% milorad dodik&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.5% europe&lt;/td&gt;
&lt;td&gt;0.6% duma&lt;/td&gt;
&lt;td&gt;0.4% bush&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.3% ukraine&lt;/td&gt;
&lt;td&gt;0.6% usg&lt;/td&gt;
&lt;td&gt;0.3% dodik&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1.2% china&lt;/td&gt;
&lt;td&gt;0.5% unsc&lt;/td&gt;
&lt;td&gt;0.3% taylor&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Another way of representing this is to plot the cumulative distribution of occurrences ordered by their frequency. The full set of entities is too big to list, but we can reveal the entities at regular intervals to get an idea of the types of names in that part of the distribution.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://knownknown.github.io/articles/01_named_entities/cumsum.PERSON.png&quot; alt=&quot;PERSON distribution&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://knownknown.github.io/articles/01_named_entities/cumsum.LOCATION.png&quot; alt=&quot;LOCATION distribution&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://knownknown.github.io/articles/01_named_entities/cumsum.ORGANIZATION.png&quot; alt=&quot;ORGANIZATION distribution&quot;&gt;&lt;/p&gt;
&lt;p&gt;The grey line here is what we would expect to see if the same number of entities were just mentioned uniformly by each cable (it’s also slightly convex because we’re ordering by frequency). The difference between these two lines is a rough metric of the diversity of the text. For example, we see that top locations reoccur much more frequently than top persons. In fact, only 48 locations account for 50% of &lt;em&gt;all&lt;/em&gt; instances where a location is mentioned (compared to 448 organizations, and 1115 persons).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Looking at the top entities, most of the locations and organizations are unsurprising and consist of common American or European terms and synonyms. The presence of Georgia and Ukraine this high on the list stands out, and is indicative of the important role those two countries play in the Russian “near-abroad”. This importance is further reflected in the abundance of references to Georgian president Saakashvili. Serbian Serbian &lt;a href=&quot;http://en.wikipedia.org/wiki/Milorad_Dodik&quot;&gt;politician&lt;/a&gt; Miloard Dodik is the only surprise and the only other foreign entity. It’s interesting to note that Dodik appears to be a continued key player in Moscow and ardent supporter of the recent Russian occupation of Crimea.&lt;/p&gt;
&lt;p&gt;One way of looking at this is that NER has reduced a set of documents containing 1.2 million lines down to the few key players with no apparent false-positives. Had we applied this approach to a secretive organization this table would already by quite useful. On the other hand, all we &lt;em&gt;really&lt;/em&gt; learned could have been gleaned by skimming through World Fact Book on the US and Russia. NER is clearly relevant, but higher-level analysis will be needed to uncover truly novel information.&lt;/p&gt;
</description>
    </item>
    <item>
      <title>WL0 - Introduction</title>
      <link>http://knownknown.github.io/articles/00_introduction/</link>
      <pubDate>Sun, 20 Apr 2014 20:00:00 -0400</pubDate>
      <guid isPermaLink="true">http://knownknown.github.io/articles/00_introduction/</guid>
      <author></author>
      <!-- passing locals.url resolves all relative urls to absolute-->
      <description>&lt;p&gt;&lt;em&gt;This is a series of articles describing data analysis, language processing, and visualization of the Wikileaks diplomatic cable data.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;more&quot;&gt;&lt;/p&gt;
&lt;p&gt;There is not yet a clear &lt;em&gt;point&lt;/em&gt; to the analyses beyond understanding how to make sense of massive, potentially important releases of interpersonal communication. This kind of information is likely to be released - willingly or not - at an even greater rate as digitization and disconnectedness becomes pervasive. Already the preferred method of concealing vital information is shifting from access limitations to obscurity by &lt;a href=&quot;http://en.wikipedia.org/wiki/Document_dump&quot;&gt;data overload&lt;/a&gt;  (see also: &lt;a href=&quot;http://www.rff.org/RFF/Documents/RFF-DP-11-45.pdf&quot;&gt;factual&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/The_Pale_King&quot;&gt;fictional&lt;/a&gt; examples). Such data demands to be made sense of, and effective tools must be developed to do so.&lt;/p&gt;
&lt;p&gt;The choice of leaked cables as study data merits a few more sentences. Though whistle-blowing is a vital element of any healthy society, blind dumps of classified government information (and that’s what the Wikileaks cache was) do not count. To put it bluntly, I strongly disagree with the Wikileaks argument that the US is less democratic because it harbours classified documents. In fact, it’s hard for me to see how a free, democratic society can durably exist without a strong security state. However, when unethical leaks do occur, the urge to avoid or ignore them is also misguided. There is no doubt that leaked data will be exploited, and as we have seen with exploits in other areas, openness and communication are the keys to limiting their abuse. An outbreak is not stemmed by pretending that it is not happening, but by recruiting the public to study its effects.&lt;/p&gt;
&lt;p&gt;If this reads too much like a manifesto I hope the reader accepts my sincere apologies. Blah blah over liberty and tyranny aside, the point here is to make some cool graphs and get a better understanding of this extremely important mess documents.&lt;/p&gt;
&lt;p&gt;The title of this series is taken, with all due respect, from the 02/28/2003 &lt;a href=&quot;http://www.defense.gov/Transcripts/Transcript.aspx?TranscriptID=1976&quot;&gt;Department of Defense briefing&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Rumsfeld: Oh, I think in the last analysis, the United States government is — daily demonstrates its inability to deal with nuance. (Laughs, laughter.) Therefore, I think what you’ll find — (laughter) — I think what you’ll find is, whatever it is we do substantively, there will be near-perfect clarity as to what it is. And it will be known, and it will be known to the Congress and it will be known to you, probably before we decide it, but it will be known. And it will have to be something that is consistent with their circumstance as well.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
  </channel>
</rss>